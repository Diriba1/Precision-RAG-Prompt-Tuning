{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from OpenAIAPIKey import openapikey as OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'OPENAI_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-driven: Trainable models leverage existing human-written test cases and prompt performance data to learn patterns and automatically generate new cases. This can be especially effective for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set your OpenAI API key\u001b[39;00m\n\u001b[0;32m      4\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-H994nsJI0Ov1em7ml1s3T3BlbkFJdxrnUiVusCkyCeqz4hCl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_test_cases_from_dataset\u001b[39m(prompt, dataset):\n\u001b[0;32m      7\u001b[0m     test_cases \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\_client.py:97\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m     95\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Set your OpenAI API key\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "client = openai.Client()\n",
    "def generate_test_cases_from_dataset(prompt, dataset):\n",
    "    test_cases = []\n",
    "    for example in dataset:\n",
    "        # Use OpenAI API to generate a variation of the example\n",
    "        response = openai.client.create_completion( \n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=f\"{prompt}. Here's an example: {example}. Generate a similar code snippet with a different approach.\",\n",
    "            max_tokens=150,  # Adjust as needed\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,  # Adjust for creativity\n",
    "        )\n",
    "\n",
    "        test_cases.append((response.choices[0].text, example))  # Include both generated and original examples\n",
    "\n",
    "    return test_cases\n",
    "\n",
    "# Load your dataset of Python code examples (replace with your actual dataset)\n",
    "dataset = [\"num = num * 2\", \"num *= 2\", \"num += num\", ...]\n",
    "\n",
    "prompt = \"Write a code snippet that doubles a given number in Python.\"\n",
    "\n",
    "# Generate test cases\n",
    "test_cases = generate_test_cases_from_dataset(prompt, dataset)\n",
    "\n",
    "# Print the generated test cases\n",
    "for generated_code, original_code in test_cases:\n",
    "    print(\"Generated Code:\", generated_code)\n",
    "    print(\"Original Code:\", original_code)\n",
    "    print(\"------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
